import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import re
import pydeck as pdk

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ—ºï¸")

st.title("ğŸ—ºï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆMapæ¤œç´¢")
st.markdown("æŒ‡å®šã—ãŸæœŸé–“ãƒ»åœ°åŸŸã®æƒ…å ±ã‚’AIãŒæ¤œç´¢ã—ã€é«˜æ©Ÿèƒ½ãƒãƒƒãƒ—ã¨ãƒªã‚¹ãƒˆã§è¡¨ç¤ºã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("æ¤œç´¢æ¡ä»¶")
    st.markdown("### ğŸ“ åœ°åŸŸãƒ»å ´æ‰€")
    region = st.text_input("æ¤œç´¢ã—ãŸã„å ´æ‰€", value="æ±äº¬éƒ½æ¸‹è°·åŒº", help="å…·ä½“çš„ãªåœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    st.markdown("---")
    
    st.markdown("### ğŸ“… æœŸé–“æŒ‡å®š")
    today = datetime.date.today()
    next_month = today + datetime.timedelta(days=30)
    
    start_date = st.date_input("é–‹å§‹æ—¥", today)
    end_date = st.date_input("çµ‚äº†æ—¥", next_month)

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("æ¤œç´¢é–‹å§‹", type="primary"):
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    if start_date > end_date:
        st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã®æ—¥ä»˜ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        # æ¤œç´¢å‡¦ç†
        client = genai.Client(api_key=api_key)
        status_text = st.empty()
        status_text.info(f"ğŸ” {region}å‘¨è¾ºã®æƒ…å ±ã‚’å³å¯†ã«åé›†ä¸­... (æƒ…å ±ã®ç²¾æŸ»ã«å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (å˜˜ã‚’é˜²ããŸã‚ã®å³æ ¼ãªæŒ‡ç¤ºã‚’è¿½åŠ )
        prompt = f"""
        ã‚ãªãŸã¯ã€Œãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚«ãƒ¼ã€ã‚’å…¼ã­ãŸãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚
        ã€{region}ã€‘ã«ãŠã‘ã‚‹ã€ã€{start_date}ã€‘ã‹ã‚‰ã€{end_date}ã€‘ã¾ã§ã®æœŸé–“ã®ä»¥ä¸‹ã®æƒ…å ±ã‚’ã€Googleæ¤œç´¢ã‚’ä½¿ã£ã¦èª¿ã¹ã¦ãã ã•ã„ã€‚

        ã€èª¿æŸ»å¯¾è±¡ã€‘
        1. æœ‰åãƒã‚§ãƒ¼ãƒ³åº—ã‚„äººæ°—é£²é£Ÿåº—ã®ã€Œæ–°ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã€ã€ŒæœŸé–“é™å®šãƒ¡ãƒ‹ãƒ¥ãƒ¼ã€ã®ç™ºå£²æƒ…å ±
        2. æ³¨ç›®ã®ã€Œæ–°è¦åº—èˆ—ã‚ªãƒ¼ãƒ—ãƒ³ã€æƒ…å ±
        3. æœŸé–“é™å®šã®ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±

        ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
        Markdownè£…é£¾ã¯ä¸è¦ã€‚ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONãƒªã‚¹ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        [
            {{
                "type": "ç¨®åˆ¥",
                "name": "åº—åã¾ãŸã¯ã‚¤ãƒ™ãƒ³ãƒˆå",
                "place": "å…·ä½“çš„ãªå ´æ‰€",
                "start_date": "YYYY-MM-DD",
                "end_date": "YYYY-MM-DD",
                "description": "æ¦‚è¦",
                "url": "å…¬å¼æƒ…å ±ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®URL(å¿…é ˆ)",
                "lat": ç·¯åº¦(æ•°å€¤),
                "lon": çµŒåº¦(æ•°å€¤)
            }},
            ...
        ]

        ã€é‡è¦ï¼šãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå˜˜ï¼‰å¯¾ç­–ã€‘
        - **æ¤œç´¢çµæœã®è¨˜äº‹ã«ã€Œ{start_date.year}å¹´ã€ã¾ãŸã¯ã€Œ{end_date.year}å¹´ã€ã®è¡¨è¨˜ãŒã‚ã‚‹ã‹å¿…ãšç¢ºèªã—ã¦ãã ã•ã„ã€‚**
        - æ—¥ä»˜ãŒä¸æ˜ç¢ºãªã‚‚ã®ã€æ˜¨å¹´ã®è¨˜äº‹ï¼ˆ2023å¹´ãªã©ï¼‰ã¯**çµ¶å¯¾ã«**å«ã‚ãªã„ã§ãã ã•ã„ã€‚
        - è©²å½“ã™ã‚‹æƒ…å ±ãŒãªã„å ´åˆã¯ã€ç„¡ç†ã«ä»¶æ•°ã‚’åŸ‹ã‚ãšã€ç¢ºå®Ÿãªã‚‚ã®ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        - å„æƒ…å ±ã® `url` ã«ã¯ã€ãã®æƒ…å ±ã®æ ¹æ‹ ã¨ãªã£ãŸWebãƒšãƒ¼ã‚¸ã®URLã‚’å¿…ãšå…¥ã‚Œã¦ãã ã•ã„ã€‚
        """

        try:
            # AIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    response_mime_type="application/json"
                )
            )

            status_text.empty()
            
            # --- JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãƒ»ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯ ---
            text = response.text.replace("```json", "").replace("```", "").strip()
            data = []
            
            try:
                data = json.loads(text)
            except json.JSONDecodeError as e:
                # ã‚¨ãƒ©ãƒ¼ãƒªã‚«ãƒãƒªãƒ¼
                try:
                    if e.msg.startswith("Extra data"):
                        data = json.loads(text[:e.pos])
                    else:
                        match = re.search(r'\[.*\]', text, re.DOTALL)
                        if match:
                            candidate = match.group(0)
                            try:
                                data = json.loads(candidate)
                            except json.JSONDecodeError as e2:
                                if e2.msg.startswith("Extra data"):
                                    data = json.loads(candidate[:e2.pos])
                                else:
                                    raise e2
                        else:
                            raise e
                except Exception:
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.stop()

            # --- æœŸé–“è¡¨ç¤ºç”¨ã®æ•´å½¢å‡¦ç† ---
            for item in data:
                s_date = item.get('start_date')
                e_date = item.get('end_date')
                if s_date and e_date:
                    if s_date == e_date:
                        item['display_date'] = s_date
                    else:
                        item['display_date'] = f"{s_date} ã€œ {e_date}"
                else:
                    item['display_date'] = s_date or "æ—¥ä»˜ä¸æ˜"

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
            df = pd.DataFrame(data)

            # --- 1. é«˜æ©Ÿèƒ½åœ°å›³ã®è¡¨ç¤º (Voyagerã‚¹ã‚¿ã‚¤ãƒ«) ---
            st.subheader(f"ğŸ“ {region}å‘¨è¾ºã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒ—")
            
            if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
                map_df = df.dropna(subset=['lat', 'lon'])
                
                view_state = pdk.ViewState(
                    latitude=map_df['lat'].mean(),
                    longitude=map_df['lon'].mean(),
                    zoom=13,
                    pitch=0,
                )

                layer = pdk.Layer(
                    "ScatterplotLayer",
                    map_df,
                    get_position='[lon, lat]',
                    get_color='[255, 75, 75, 160]',
                    get_radius=200,
                    pickable=True,
                )

                st.pydeck_chart(pdk.Deck(
                    map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                    initial_view_state=view_state,
                    layers=[layer],
                    tooltip={
                        "html": "<b>{name}</b><br/>{place}<br/><i>{description}</i>",
                        "style": {"backgroundColor": "steelblue", "color": "white"}
                    }
                ))
                st.caption("â€»åœ°å›³ä¸Šã®èµ¤ã„ä¸¸ã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
                # CSVä½œæˆ
                export_data = []
                for _, row in map_df.iterrows():
                    gaiyou = f"ã€æœŸé–“ã€‘{row.get('display_date')}\n{row.get('description')}"
                    export_data.append({
                        "Name": row.get('name'),
                        "ä½æ‰€": row.get('place'),
                        "æ¦‚è¦": gaiyou,
                        "å…¬å¼ã‚µã‚¤ãƒˆ": row.get('url', '')
                    })
                
                export_df = pd.DataFrame(export_data)
                csv = export_df.to_csv(index=False).encode('utf-8_sig')

                st.download_button(
                    label="ğŸ“¥ Googleãƒã‚¤ãƒãƒƒãƒ—ç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"event_map_{region}.csv",
                    mime='text/csv',
                    help="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã€Œä½æ‰€ã€åˆ—ã‚’ç›®å°ã®å ´æ‰€ã«æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
                )

            else:
                st.warning("åœ°å›³ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢çµæœãŒå°‘ãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            # --- 2. é€Ÿå ±ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆï¼ˆæ¤œè¨¼ãƒªãƒ³ã‚¯ä»˜ãï¼‰ ---
            st.markdown("---")
            st.subheader("ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ä¸€è¦§ï¼ˆè¦ç¢ºèªï¼‰")
            st.caption("â€»AIã®æ¤œç´¢çµæœã«ã¯èª¤ã‚ŠãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å¿…ãšã€Œã‚½ãƒ¼ã‚¹ã€ã®ãƒªãƒ³ã‚¯ã‹ã‚‰çœŸå½ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
            for item in data:
                url_text = "ãªã—"
                if item.get('url'):
                    # ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã‚„ã™ãç›®ç«‹ãŸã›ã‚‹
                    url_text = f"[ğŸ”— æ¤œç´¢å…ƒã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã™ã‚‹]({item.get('url')})"

                st.markdown(f"""
                - **æœŸé–“**: {item.get('display_date')}
                - **ç¨®åˆ¥**: {item.get('type')}
                - **åº—å/ã‚¤ãƒ™ãƒ³ãƒˆå**: {item.get('name')}
                - **å ´æ‰€**: {item.get('place')}
                - **æ¦‚è¦**: {item.get('description')}
                - **ã‚½ãƒ¼ã‚¹**: {url_text}
                """)
            
            # Groundingã‚½ãƒ¼ã‚¹ï¼ˆå¿µã®ãŸã‚æ®‹ã™ï¼‰
            with st.expander("ğŸ“š AIãŒå‚ç…§ã—ãŸWebãƒšãƒ¼ã‚¸ä¸€è¦§"):
                if response.candidates[0].grounding_metadata.grounding_chunks:
                    for chunk in response.candidates[0].grounding_metadata.grounding_chunks:
                        if chunk.web:
                            st.markdown(f"- [{chunk.web.title}]({chunk.web.uri})")

        except Exception as e:
            status_text.empty()
            st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
